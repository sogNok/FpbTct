{"cells":[{"cell_type":"markdown","metadata":{"id":"DUb1pg2m6RJu"},"source":["# Lab 10-3: YOLO for Object Detection\n","## Exercise: Implement YOLO v1 Loss Function"]},{"cell_type":"markdown","metadata":{"id":"IgRSipEm5_FI"},"source":["Verifying a loss function for object detection requires special ground truth and prediction result,\n","otherwise the loss value could be meaningless."]},{"cell_type":"code","execution_count":59,"metadata":{"executionInfo":{"elapsed":334,"status":"ok","timestamp":1658488944985,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"x6hAoLrarRFL"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","n_batch = 2\n","\n","o_locatn = np.zeros((n_batch,7,7))\n","\n","y_tr = np.zeros(shape=(n_batch,7,7,30), dtype=float)\n","y_tm = np.zeros(shape=(n_batch,7,7,30), dtype=float)\n","\n","np.random.seed(6)\n","\n","for n in range(n_batch):\n","\n","    obj_bbox = np.random.rand(8,4)\n","    prd_bbox = np.clip(obj_bbox + (np.random.randn(8,4) * 0.05), a_min=0.0, a_max=1.0-1e-8)\n","    n_object = np.random.randint(low=4, high=8)\n","    \n","    for i in range(n_object):\n","        tbox = np.zeros((4))\n","        tbox[0:2] = np.minimum(obj_bbox[i,0:2], obj_bbox[i,2:4]) # y,x of bottom left\n","        tbox[2:4] = np.maximum(obj_bbox[i,0:2], obj_bbox[i,2:4]) # y,x of top right\n","        c_y, c_x = (tbox[0:2] + tbox[2:4]) / 2   # y,x of center\n","        c_h, c_w = tbox[2:4] - tbox[0:2]         # h,w of bbox\n","        i_y, i_x = int(c_y*7), int(c_x*7)\n","        c_y, c_x = c_y*7 - i_y, c_x*7 - i_x\n","        # for yolov2: tbx1 & tbx2 represent different anchors\n","        tbx1 = np.array([1.0, c_y, c_x, c_h, c_w])  # true box coordinate\n","        tbx2 = np.array([0.0, c_y, c_x, c_h, c_w])  # set confidence 0; null box\n","        clss = np.zeros((20))\n","        clss[np.random.randint(20)] = 1.0\n","        y_tr[n, i_y, i_x] = np.concatenate((tbx1, tbx2, clss), axis=0)\n","\n","        o_locatn[n, i_y, i_x] = 1.0  # not in true tensor, just display purpose\n","    \n","        pbox = np.zeros((4))\n","        pbox[0:2] = np.minimum(prd_bbox[i,0:2], prd_bbox[i,2:4]) # y,x of bottom left\n","        pbox[2:4] = np.maximum(prd_bbox[i,0:2], prd_bbox[i,2:4]) # y,x of top right\n","        c_y, c_x = (pbox[0:2] + pbox[2:4]) / 2 # y,x of center\n","        c_h, c_w = pbox[2:4] - pbox[0:2]       # h,w of bbox\n","        i_y, i_x = int(c_y*7), int(c_x*7)\n","        c_y, c_x = c_y*7 - i_y, c_x*7 - i_x\n","        # for yolov2: pbx1 & pbx2 represent different anchors\n","        cnf1 = 0.3 if np.random.random()>0.5 else 0.7\n","        cnf2 = 1.0 - cnf1\n","        pbx1 = np.array([cnf1, c_y, c_x, c_h, c_w])\n","        pbx2 = np.array([cnf2, c_y, c_x, c_h, c_w])\n","        y_tm[n, i_y, i_x] = np.concatenate((pbx1, pbx2, clss), axis=0)\n","    \n","    y_pr = y_tm + np.random.randn(7,7,30) * 0.01\n","\n","y_true = tf.cast(y_tr, dtype=tf.float32)\n","y_pred = tf.cast(y_pr, dtype=tf.float32)"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"x5LHn6Iu5_FL","executionInfo":{"status":"ok","timestamp":1658488946839,"user_tz":-540,"elapsed":534,"user":{"displayName":"이충섭","userId":"17624345601773915567"}},"outputId":"da27bdd2-a883-4969-9fd3-5c2b90d75a31"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 1. 1. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1. 0.]\n"," [0. 1. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0.]]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["print(o_locatn[0])\n","\n","sample = np.zeros((448,448,3))\n","img_h, img_w, _ = sample.shape\n","plt.imshow(sample)\n","axs = plt.gca()   # get current axes\n","\n","for j in range(7):\n","    for i in range(7):\n","        if y_true[0,j,i,0]==1:\n","            c_y, c_x, c_h, c_w = y_true[0,j,i,1:5]\n","            c_y, c_x = (c_y + j)/7, (c_y + i)/7\n","            obj_y, obj_x, obj_h, obj_w = (c_y-c_h/2)*img_h, (c_x-c_w/2)*img_w, c_h*img_h, c_w*img_w\n","            bbox = patches.Rectangle((obj_x,obj_y), obj_w, obj_h, 0, linewidth=2, edgecolor='limegreen', fill = False)\n","            axs.add_patch(bbox)\n","            plt.text(obj_x+1, obj_y+17, str(j)+str(i), color='yellow')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"oPkFRj3y5_FN"},"source":["### Loss Function for YOLO v1\n","\n","$$ \\lambda_{coord} \\sum_{i=0}^{S^2} \\sum_{j=0}^{B} \\bold{1}_{ij}^{obj} \\left[ (x_i - \\hat{x}_i)^2+(y_i - \\hat{y}_i)^2 \\right] \n","+\\lambda_{coord} \\sum_{i=0}^{S^2} \\sum_{j=0}^{B} \\bold{1}_{ij}^{obj} \\left[ \\left( \\sqrt{w_i} - \\sqrt{\\hat{w}_i} \\right)^2 \n","+ \\left(\\sqrt{h_i} - \\sqrt{\\hat{h}_i} \\right)^2 \\right] $$\n","$$ + \\sum_{i=0}^{S^2} \\sum_{j=0}^{B} \\bold{1}_{ij}^{obj} \\left( c_i - \\hat{c}_i \\right)^2 \n","+\\lambda_{noobj} \\sum_{i=0}^{S^2} \\sum_{j=0}^{B} \\bold{1}_{ij}^{noobj} \\left( c_i - \\hat{c}_i \\right)^2 $$\n","$$ + \\sum_{i=0}^{S^2} \\bold{1}_{ij}^{obj} \\sum_{c \\in classes} \\left( p_i(c) - \\hat{p}_i (c) \\right)^2 $$\n","\n","**Note:** The original YOLO v1 evaluates object confidence and object class with MSE even though they are probabilities.<br>\n","In this implementation you can use sigmoid and softmax to make the convergence of the model more stable."]},{"cell_type":"code","execution_count":69,"metadata":{"executionInfo":{"elapsed":804,"status":"ok","timestamp":1658489117508,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"6BZHsHKVrRFU"},"outputs":[],"source":["def yolo_loss_fn(y_true, y_pred):\n","    \n","    l_coord = 5.0  # lambda_coord\n","    l_noobj = 0.5  # lambda_noobj\n","    n_grid = 7\n","    n_batch = tf.shape(y_true)[0]\n","\n","    # make a matrix of grid index\n","    idx_no0 = tf.reshape(tf.range(0, n_grid, dtype=tf.float32), [1,n_grid,1,1,1]) # (1,g,1,1,1)\n","    idx_no1 = tf.repeat(idx_no0, repeats=n_grid, axis=2) # (1,g,g,1,1)\n","    idx_no2 = tf.transpose(idx_no1, [0,2,1,3,4])         # (1,g,g,1,1)\n","    idx_ar0 = tf.concat([idx_no1,idx_no2], axis=-1)      # (1,g,g,1,2)\n","    # make two matrices of grid index\n","    idx_arr = tf.repeat(idx_ar0, repeats=2, axis=-2)     # (1,g,g,2,2)\n","\n","    # (1) yolo_head for y_true: box_confidence, box_yx, box_hw, box_class_probs\n","    # for yolov1, only 1 true object per grid is used\n","    # Since there are two sets of box proposals, duplicate ground truth for easy comparison\n","    y_true_1c = tf.expand_dims(y_true, axis=-2)          # make a room (new axis) at -2 to repeat\n","    y_true_2c = tf.repeat(y_true_1c, repeats=2, axis=-2) # make two copies of truth for easy computation\n","\n","    ### START CODE HERE ###\n","    \n","    # copy true_box_yx (offset) and apply grid location\n","    true_o_yx = y_true_2c[..., 1:3]                # get (y,x) offset from y_true_2c\n","    true_c_yx = (true_o_yx + idx_arr) /  tf.cast(tf.reshape(tf.constant([n_grid, n_grid]), [1, 1, 1, 1, 2]), dtype=y_true_2c.dtype)               # apply grid position and normalize them\n","    true_c_hw = tf.exp(y_true_2c[..., 3:5])                # convert (h,w) in exp\n","\n","    # copy true_one_hot_classes\n","    true_clss = y_true[..., 10:]                # get true class from y_true_2c\n","    \n","    ### END CODE HERE ###\n","    \n","    print('(1)', true_c_yx[0,2,3,0].numpy(), true_c_hw[0,2,3,0].numpy())\n","\n","    # (2) yolo_head for y_pred: box_confidence, box_yx, box_hw, box_class_probs\n","    # for yolov1, 2 prediction proposals per grid is used\n","    # reshape one row of two proposals into two by five of two proposals\n","    y_pred_rs = tf.reshape(y_pred[..., :10], [n_batch,n_grid,n_grid,2,5]) # (b,g,g,2,5)\n","    \n","    ### START CODE HERE ###\n","\n","    # take the predicted confidence and put it into [0,1] by sigmoid\n","    pred_conf = tf.sigmoid(y_pred_rs[..., 0])                # dimension: (b,g,g,2) = (c1,c2)\n","\n","    # take the y,x coordinates and apply gird location\n","    pred_o_yx = y_pred_rs[..., 1:3]                # get (y,x) offset from y_pred_rs\n","    pred_c_yx = (pred_o_yx + idx_arr) /  tf.cast(tf.reshape(tf.constant([n_grid, n_grid]), [1, 1, 1, 1, 2]), dtype=y_pred_rs.dtype)                # apply grid position and normalize them\n","\n","    # take the h,w lenths and feed to exponential function.\n","    pred_c_hw = tf.exp(y_pred_rs[..., 3:])\n","\n","    # take the predicted one-hot classes and apply softmax\n","    pred_clss = tf.nn.softmax(y_pred[..., 10:], axis=-1)\n","  \n","    ### END CODE HERE ###\n","\n","    print('(2)', pred_c_yx[0,2,3,0].numpy(), pred_c_hw[0,2,3,0].numpy())\n","\n","    # (3) Now find the correct prediction of high iou with ground truth\n","    ### START CODE HERE ###\n","\n","    # find bottom coner and top coner coordinates of true box and predicted box\n","    true_b_yx = true_c_yx - true_c_hw / 2                # true b(y,x)\n","    true_t_yx = true_c_yx + true_c_hw / 2                # true t(y,x)\n","    pred_b_yx = pred_c_yx - pred_c_hw / 2                # pred b(y,x)\n","    pred_t_yx = pred_c_yx + pred_c_hw / 2                # pred t(y,x)\n","\n","    # find h&w of overlapped area (intersection); how to make h&w positive?\n","    ovrl_b_yx = tf.maximum(true_b_yx, pred_b_yx)\n","    ovrl_t_yx = tf.minimum(true_t_yx, pred_t_yx)\n","    ovrl_bxhw = tf.maximum(ovrl_t_yx - ovrl_b_yx, tf.constant([0.0,0.0]))\n","\n","    # calculate areas; ground truth, prediction, and overlapped.\n","    true_area = tf.reduce_prod(true_c_hw, axis=-1)\n","    pred_area = tf.reduce_prod(pred_c_hw, axis=-1)\n","    ovrl_area = tf.reduce_prod(ovrl_bxhw, axis=-1)\n","\n","    # calculate IoU; score for predicted objects\n","    iou_value = tf.divide(ovrl_area, true_area + pred_area - ovrl_area)\n","    \n","    ### END CODE HERE ###\n","\n","    print('(3)', iou_value[0,2,3].numpy())\n","\n","    # (4) Generate true object & true non-object mask with the location of higher iou prediction\n","    ### START CODE HERE ###\n","\n","    # find mask for higher iou prediction\n","    # iou_bigger is a matrix that indicate higher; range 0:1/1:2 are used to keep dimension\n","    iou_biggr = tf.cast(iou_value[...,0:1] >= iou_value[...,1:2], iou_value.dtype) \n","    iou_smalr = tf.cast(iou_value[...,0:1] < iou_value[...,1:2], iou_value.dtype)                # (b,g,g,1)\n","    iou_bmssk = tf.concat([iou_biggr, iou_smalr], axis=-1)                # (b,g,g,2) = mask with higher iou\n","\n","    # find object (with high iou prediction) and no-object masks (low iou prediction) \n","    true_objt = tf.repeat(y_true[..., 0:1], repeats=2, axis=-1)                # grid with object taken from y_true\n","    true_objc = true_objt * iou_bmssk                # 1obj = obj & h-iou\n","    true_nbjc = tf.where(true_objc > 0.0, 0.0, 1.0) # tf.where(true_objc > 0.0, 0.0, 1.0)                # 1noobj = nbj | l_iou\n","\n","    ### END CODE HERE ###\n","\n","    print('(4)', true_objc[0,2,3].numpy(), true_nbjc[0,2,3].numpy())\n","\n","    # finally calculate individual loss value for each criterion\n","    ### START CODE HERE ###\n","\n","    # calculate coordinate loss\n","    # [(xt-xp)^2+(yt-yp)^2]*1obj\n","    loss_cyx0 = tf.reduce_sum(tf.square(true_c_yx - pred_c_yx), axis=-1)\n","    loss_c_yx = tf.reduce_sum(true_objc * loss_cyx0, axis=[1,2,3])\n","\n","    # [(wt^.5-wp^.5)^2,(ht^.5-hp^.5)^2]*1obj\n","    loss_chw0 = tf.reduce_sum(tf.square(tf.sqrt(true_c_hw)  - tf.sqrt(pred_c_hw)), axis=-1)\n","    loss_c_hw = tf.reduce_sum(true_objc * loss_chw0, axis=[1,2,3])\n","\n","    loss_coordinate = l_coord * (loss_c_yx + loss_c_hw) # (b,)\n","    \n","    # calculate confidence loss; first, generate mask for obj & noobj of 4D\n","    loss_ob_c = tf.reduce_sum(true_objc * tf.square(y_true_2c[..., 0] - pred_conf), axis=[1,2,3])\n","    loss_nb_c = tf.reduce_sum(true_nbjc * tf.square(y_true_2c[..., 0] - pred_conf), axis=[1,2,3])\n","\n","    loss_confidence = loss_ob_c + l_noobj * loss_nb_c # (b,)\n","\n","    # calculate classification loss\n","    loss_clss = tf.reduce_sum(tf.square(true_clss - pred_clss), axis=-1)\n","    loss_classification = tf.reduce_sum(true_objt[..., 0] * loss_clss, axis=[1,2]) # (b,)\n","\n","    ### END CODE HERE ###\n","\n","    loss = tf.reduce_mean(loss_coordinate + loss_confidence + loss_classification)\n","\n","    return loss, loss_coordinate, loss_confidence, loss_classification"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":333,"status":"ok","timestamp":1658489120005,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"yYZzrqCfrRFX","outputId":"628500b2-3521-4167-ee08-08626e7587e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1) [0.31873703 0.50692976] [1.5252535 1.1927298]\n","(2) [0.29914564 0.4825395 ] [1.4983883 1.3369714]\n","(3) [0.8713145 0.887088 ]\n","(4) [0. 1.] [1. 0.]\n","18.194208\n","0.94476545 13.074263 5.916487\n"]}],"source":["loss, loss_yxhw, loss_conf, loss_clss = yolo_loss_fn(y_true, y_pred)\n","\n","print(loss.numpy())\n","print(loss_yxhw[0].numpy(), loss_conf[0].numpy(), loss_clss[0].numpy())"]},{"cell_type":"markdown","metadata":{"id":"Nk3rsDP35_FP"},"source":["**Expected Output**\n","```\n","(1) [0.31873703 0.50692976] [1.5252537 1.1927298]\n","(2) [0.29914564 0.4825395 ] [1.4983883 1.3369714]\n","(3) [0.8713146  0.88708806]\n","(4) [0. 1.] [1. 0.]\n","18.068064\n","0.94476557 13.39139 5.268878\n","```"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"ML_L10_03_YOLOv1loss_dist.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.12 ('tf2')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"71930d9c743a2c2f7d41567bb1e631f1d30be1b0f7ff3429fb86acce8edbed56"}}},"nbformat":4,"nbformat_minor":0}