{"cells":[{"cell_type":"markdown","metadata":{"id":"DUb1pg2m6RJu"},"source":["# Lab 08-2: DNNs with TensorFlow\n","## Exercise: Predicting MNIST Digits"]},{"cell_type":"markdown","metadata":{"id":"CRV6ou8SK1no"},"source":["Prepare MNIST Dataset"]},{"cell_type":"code","execution_count":112,"metadata":{"executionInfo":{"elapsed":955,"status":"ok","timestamp":1657805255203,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"NW9z3LVwt4_n"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import time\n","\n","# tf.config.set_visible_devices([], 'GPU')\n","\n","# Load the original MNIST dataset\n","# MNIST dataset contains 60000 training images and 10000 test images of 28x28 pixels\n","# Each image has a hand-written digit\n","(X_train_org, y_train_num), (X_test_org, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","# flatten the last dimension for DNN\n","X_train_org = tf.reshape(X_train_org, (X_train_org.shape[0], -1))\n","X_test_org = tf.reshape(X_test_org, (X_test_org.shape[0], -1))\n","\n","# Digits data has range of [0,255], which often lead too big exponential values\n","# so make them normal distribution of [0,1] with the sklearn package, or you can just divide them by 255\n","X_train = tf.cast(X_train_org / 255, dtype=tf.float32)\n","X_test = tf.cast(X_test_org / 255, dtype=tf.float32)\n","\n","# Transform Nx1 Y vector to Nx10 answer vector, so that we can perform one-to-all classification\n","y_train = tf.one_hot(y_train_num, 10)\n","\n","# Split training dataset into training and validation\n","X_val = X_train[50000:60000]\n","y_val = y_train[50000:60000]\n","\n","X_train = X_train[:50000]\n","y_train = y_train[:50000]\n","\n","n_classes = 10\n","n_features = 784"]},{"cell_type":"markdown","metadata":{"id":"C9n0T8tiK_Sg"},"source":["Predifined Functions"]},{"cell_type":"code","execution_count":113,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1657805255203,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"xXm6ItNTuA2V"},"outputs":[],"source":["def create_mini_batches(X, y, batch_size=64):\n","    mini_batches = []\n","    data = tf.concat([X, y], axis=-1)\n","    tf.random.shuffle(data)\n","    n_classes = y.shape[1]\n","    n_minibatches = (data.shape[0] // batch_size)\n","  \n","    for i in range(n_minibatches):\n","        mini_batch = data[i * batch_size:(i + 1)*batch_size, :]\n","        X_mini = mini_batch[:, :-n_classes]\n","        Y_mini = mini_batch[:, -n_classes:]\n","        mini_batches.append((X_mini, Y_mini))\n","    \n","    if data.shape[0] % batch_size != 0:\n","        mini_batch = data[n_minibatches * batch_size:data.shape[0]]\n","        X_mini = mini_batch[:, :-n_classes]\n","        Y_mini = mini_batch[:, -n_classes:]\n","        mini_batches.append((X_mini, Y_mini))\n","        \n","    return mini_batches"]},{"cell_type":"markdown","metadata":{"id":"aFuH2mWzLDdV"},"source":["## Network Definition with TensorFlow Core (Low Level)\n","In this exercise, do not use keras layers."]},{"cell_type":"code","execution_count":114,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1657805255204,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"bbsv3-wquD8n"},"outputs":[],"source":["class tfDense(tf.Module):\n","\n","    def __init__(self, n_out, n_in, activation='relu', rate=0.0, batchnorm=False, name=None):\n","        super().__init__(name=name)\n","        self.activation = activation\n","        self.rate = rate\n","        self.batchnorm = batchnorm\n","        # variables for Dense layer\n","        self.w = tf.Variable(tf.zeros([n_in, n_out]), name='w')             # weight\n","        self.b = tf.Variable(tf.zeros([n_out]), name='b')                   # bias\n","        # variables for batch normalization\n","        self.mn = tf.Variable(tf.zeros([n_out]), trainable=False, name='m') # running mean for BN\n","        self.va = tf.Variable(tf.ones([n_out]), trainable=False, name='v')  # running variance for BN\n","        self.gm = tf.Variable(tf.ones([n_out]), name='s')                   # gamma (=scale) for BN\n","        self.bt = tf.Variable(tf.zeros([n_out]), name='o')                  # beta (=offset) for BN\n","        self.mm = 0.9                                                       # momentum parameter for BN\n","\n","    def __call__(self, x, training=False):\n","        ### START CODE HERE ###\n","        \n","        x = tf.matmul(x, self.w) + self.b       # linear prediction\n","        \n","        # batch normalization\n","        if self.batchnorm:\n","            tmp_mn, tmp_va = self.mn, self.va\n","            if training:\n","                new_mn, new_va = tf.nn.moments(x, axes=[0])    # find mean and variance; check tf.nn.moments\n","                self.mn = self.mm * self.mn + (1 - self.mm) * new_mn           # update running mean\n","                self.va = self.mm * self.va + (1 - self.mm) * new_va           # update running variance\n","                tmp_mn, tmp_va = new_mn, new_va\n","            x = tf.nn.batch_normalization(x, tmp_mn, tmp_va, self.gm, self.bt, 1e-8)                     # batch_normalization function; check tf.nn.batch_normalization\n","        \n","        # activation function\n","        if self.activation=='sigmoid':\n","            x = tf.math.sigmoid(x)\n","        elif self.activation=='softmax':\n","            x = tf.nn.softmax(x)\n","        elif self.activation=='relu':\n","            x = tf.nn.relu(x)\n","        else: \n","            print('activation type error')\n","        \n","        # dropout\n","        x = tf.nn.dropout(x, rate=self.rate)                         # dropout is only used in training mode; check tf.nn.dropout\n","\n","        ### END CODE HERE ###\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"NnOUm9OzC8kM"},"source":["Create a DNN model"]},{"cell_type":"code","execution_count":115,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1657805255204,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"uJNy9l6p1RyY"},"outputs":[],"source":["# define network\n","n_hd1 = 100\n","n_hd2 = 60\n","n_hd3 = 30\n","\n","l1 = tfDense(n_out=n_hd1, n_in=n_features, activation='relu', rate=0.5, batchnorm=False)\n","l2 = tfDense(n_out=n_hd2, n_in=n_hd1, activation='relu', rate=0.0, batchnorm=True)\n","l3 = tfDense(n_out=n_hd3, n_in=n_hd2, activation='relu', rate=0.0, batchnorm=True)\n","l4 = tfDense(n_out=n_classes, n_in=n_hd3, activation='softmax', rate=0.0, batchnorm=False)\n","\n","vars = [l1.w, l1.b, l2.w, l2.b, l2.gm, l2.bt, l3.w, l3.b, l3.gm, l3.bt, l4.w, l4.b]"]},{"cell_type":"markdown","metadata":{"id":"I-Le0dLoDTn8"},"source":["Define Training Functions"]},{"cell_type":"code","execution_count":116,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1657805255204,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"VQG_FehgDXWM"},"outputs":[],"source":["# def my_forward(l1, l2, l3, l4, X_in, y_true, training=False):\n","# def my_backward(l1, l2, l3, l4, X_in, y_true):\n","# We are going to use GradientTape, so no more forward & backward definition \n","\n","def my_loss(l1, l2, l3, l4, X_in, y_true, training=False):\n","    ### START CODE HERE ###\n","\n","    # calculate loss\n","    a_1 = l1.__call__(X_in, training=training)                       # first layer\n","    a_2 = l2.__call__(a_1, training=training)                       # second layer\n","    a_3 = l3.__call__(a_2, training=training)                       # third layer\n","    a_4 = l4.__call__(a_3, training=training)                       # last layer\n","    loss = -tf.reduce_mean(y_true * tf.math.log(a_4))                      # calculate loss\n","\n","    # calculate accuracy; correct prediction over total prediction\n","    cmp = tf.where(y_true)[:,1] == tf.argmax(a_4, axis=1)                       # is it correct?\n","    acc = tf.reduce_mean(tf.cast(cmp, dtype=tf.float16))                       # how many prediction is correct?\n","\n","    ### END CODE HERE ###\n","    return loss, acc\n","    \n","def my_predict(l1, l2, l3, l4, X_in):\n","    ### START CODE HERE ###\n","\n","    a_1 = l1.__call__(X_in)                       # first layer prediction\n","    a_2 = l2.__call__(a_1)                       # second layer prediction\n","    a_3 = l3.__call__(a_2)                       # third layer prediction\n","    a_4 = l4.__call__(a_3)                       # last layer prediction\n","    pred = tf.argmax(a_4, axis=1)                      # determine class\n","\n","    ### END CODE HERE ###\n","    return pred"]},{"cell_type":"markdown","metadata":{"id":"cz-9OzwFDjW7"},"source":["Initialize Weights"]},{"cell_type":"code","execution_count":117,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1657805255205,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"4lC_u4DlDniG"},"outputs":[],"source":["def my_initializer(lyr, pdf='normal'):\n","    w_shape = lyr.w.shape            # (i,c)\n","    fan_in, fan_out = w_shape\n","\n","    if pdf=='he_normal':\n","        lyr.w = tf.random.normal(w_shape) * tf.sqrt(2/fan_in)\n","    elif pdf=='xavier_normal':\n","        lyr.w = tf.random.normal(w_shape) * tf.sqrt(2/(fan_out + fan_in))\n","    elif pdf=='normal':\n","        lyr.w = tf.random.normal(w_shape)\n","    else:\n","        print('initializer error')\n","\n","    return\n","\n","# Weights are initialized to...\n","my_initializer(l1, pdf='he_normal')\n","my_initializer(l2, pdf='he_normal')\n","my_initializer(l3, pdf='he_normal')\n","my_initializer(l4, pdf='he_normal')"]},{"cell_type":"markdown","metadata":{"id":"kTrLwzVALI8F"},"source":["### Deep Neural Network Using GradientTape"]},{"cell_type":"code","execution_count":118,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"SMrDLsOluG4W","outputId":"29a7f646-4741-455d-8ae0-3eefc4ba3906","executionInfo":{"status":"error","timestamp":1657805290366,"user_tz":-540,"elapsed":35166,"user":{"displayName":"이충섭","userId":"17624345601773915567"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch:    2 Elapsed_t: 11.30s loss: 0.18529400 - val_loss: 0.17627473 val_acc: 0.41015625\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-118-a2faa8df28d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Forward Prediction Path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_mini\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mini\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Backward Gradient Path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-116-46e617b9ddba>\u001b[0m in \u001b[0;36mmy_loss\u001b[0;34m(l1, l2, l3, l4, X_in, y_true, training)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0ma_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m                       \u001b[0;31m# first layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0ma_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m                       \u001b[0;31m# second layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0ma_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m                       \u001b[0;31m# third layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0ma_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m                       \u001b[0;31m# last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m                      \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-114-7bf608baa144>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mnew_mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# find mean and variance; check tf.nn.moments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnew_mn\u001b[0m           \u001b[0;31m# update running mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mva\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mva\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnew_va\u001b[0m           \u001b[0;31m# update running variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mtmp_mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_va\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1754\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m--> 463\u001b[0;31m         _ctx, \"AddV2\", name, x, y)\n\u001b[0m\u001b[1;32m    464\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["alpha = 0.001\n","opt = tf.optimizers.Adam(alpha)\n","\n","n_epochs = 30\n","\n","for epoch in range(n_epochs):\n","\n","    start = time.time()    \n","    loss_J = 0\n","    mini_batches = create_mini_batches(X_train, y_train, batch_size=64)\n","\n","    for mini_batch in mini_batches:\n","        X_mini, y_mini = mini_batch\n","        mb_len = X_mini.shape[0]\n","\n","        # Forward Prediction Path\n","        with tf.GradientTape() as tape:\n","            loss, acc = my_loss(l1, l2, l3, l4, X_mini, y_mini, training=True)\n","\n","        # Backward Gradient Path\n","        grad = tape.gradient(loss, vars)\n","        opt.apply_gradients([(grd, var) for (grd, var) in zip(grad, vars)\n","                             if grd is not None])\n","\n","        loss_J += loss\n","    \n","    loss_J = loss_J / (X_train.shape[0]/64)\n","\n","    # Just to show progress\n","    if ((epoch+1)%2==0):\n","        loss_V, acc_V = my_loss(l1, l2, l3, l4, X_val, y_val, training=False)\n","        tf.print('Epoch: %4d' % (epoch+1), 'Elapsed_t: %4.2fs' % (time.time()-start), 'loss: %10.8f' % (loss_J),\n","                 '- val_loss: %10.8f' % (loss_V), 'val_acc: %10.8f' % (acc_V))"]},{"cell_type":"markdown","metadata":{"id":"bu8nWSyvLM0n"},"source":["Network Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3kVCzh6iuLmV","executionInfo":{"status":"aborted","timestamp":1657805290365,"user_tz":-540,"elapsed":5,"user":{"displayName":"이충섭","userId":"17624345601773915567"}}},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","y_prd = my_predict(l1, l2, l3, l4, X_test)\n","\n","print(y_test[0:10])\n","print(y_prd[0:10].numpy())\n","\n","accuracy_score(y_prd, y_test)\n"]},{"cell_type":"markdown","metadata":{"id":"rfDtrCs9LSIF"},"source":["Test Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wNsHUeP6uP0Q","executionInfo":{"status":"aborted","timestamp":1657805290366,"user_tz":-540,"elapsed":5,"user":{"displayName":"이충섭","userId":"17624345601773915567"}}},"outputs":[],"source":["idx = np.random.randint(X_test_org.shape[0])\n","plt.matshow(tf.reshape(X_test_org[idx], (28,28)))\n","plt.gray()\n","plt.show()\n","\n","X_in = tf.expand_dims(X_test[idx],0)\n","\n","y_pred = my_predict(l1, l2, l3, l4, X_in)\n","\n","print('My prediction is ' + str(y_pred[0].numpy()))\n","print('Actual number is ' + str(y_test[idx]))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"ML_L08_02_DNN2_dist.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":0}