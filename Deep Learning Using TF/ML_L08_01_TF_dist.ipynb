{"cells":[{"cell_type":"markdown","metadata":{"id":"TkDeriUxmn0_"},"source":["# Lab 08-1: Logistic Regression with TensorFlow\n","## Exercise: Predicting MNIST Digits"]},{"cell_type":"markdown","metadata":{"id":"TJqg5mGiFnxm"},"source":["Import TensorFlow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3159,"status":"ok","timestamp":1657286557889,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"9TZwRQapFnxz","outputId":"cb99d40e-56c4-4484-cc63-d5989ce6126a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available:  1\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"markdown","metadata":{"id":"8cmWV58QFnx9"},"source":["Test Some TensorFlow codes"]},{"cell_type":"markdown","metadata":{"id":"PSpX1MOvrb_S"},"source":["### Notice for Implementation with TensorFlow\n","In the previous classes, we define weight as (n_out, n_in), which leads<br>\n","h = matmul(w, x.T).T + b., where the first dimension is the batch.<br>\n","By applying transpose into the parenthesis, we get<br>\n","h = matmul(x, w.T) + b<br>\n","Now if we define weight as (n_in, n_out), the linear transformation becomes<br>\n","h = matmul(x, w) + b<br>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3750,"status":"ok","timestamp":1657286565107,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"mX9mo2JaFnx-","outputId":"0fbf4ebd-619a-4629-c38b-243a7c89e397"},"outputs":[{"output_type":"stream","name":"stdout","text":["(100,) (784, 100) (2, 100)\n"]}],"source":["b = tf.Variable(tf.zeros((100,)))\n","w = tf.Variable(tf.random.uniform((784, 100)))\n","x = tf.constant(1., shape=(2, 784))\n","h = tf.nn.relu(tf.matmul(x, w) + b)\n","\n","print(b.shape, w.shape, h.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1657286565108,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"0Vo6HkDuFnyA","outputId":"b9fe7aca-afb6-4ab5-b18a-09c50cb66899"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(7.0, shape=(), dtype=float32)\n"]}],"source":["node1 = tf.constant(3.0)\n","node2 = tf.constant(4.0)\n","node3 = node1 + node2\n","\n","print(node3)"]},{"cell_type":"markdown","metadata":{"id":"y6lQbhj6FnyD"},"source":["Prepare MNIST Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"elapsed":981,"status":"ok","timestamp":1657286566078,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"YvpfcrMbGGbc","outputId":"45517d5d-d23f-4dfe-8ddf-2949aadf09de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 288x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["The number is 3\n"]}],"source":["# Load the original MNIST dataset\n","# MNIST dataset contains 60000 training images and 10000 test images of 28x28 pixels\n","# Each image has a hand-written digit\n","(X_train_org, y_train_num), (X_test_org, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","idx = np.random.randint(X_test_org.shape[0])\n","plt.matshow(X_test_org[idx])\n","plt.gray()\n","plt.show()\n","print('The number is', y_test[idx])\n","\n","# flatten the last dimension for DNN\n","X_train_org = X_train_org.reshape((X_train_org.shape[0], -1))\n","X_test_org = X_test_org.reshape(X_test_org.shape[0], -1)"]},{"cell_type":"markdown","metadata":{"id":"YiyJhX7T0VZL"},"source":["Split training dataset into train and validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rt-xKglsFnyE"},"outputs":[],"source":["# Digits data has range of [0,255], which often lead too big exponential values\n","# so make them normal distribution of [0,1] with the sklearn package, or you can just divide them by 255\n","X_train = tf.cast(X_train_org / 255, dtype=tf.float32)\n","X_test = tf.cast(X_test_org / 255, dtype=tf.float32)\n","\n","# Transform Nx1 Y vector to Nx10 answer vector, so that we can perform one-to-all classification\n","y_train = tf.one_hot(y_train_num, 10)\n","\n","# Split training dataset into training and validation\n","X_val = X_train[50000:60000]\n","y_val = y_train[50000:60000]\n","\n","X_train = X_train[:50000]\n","y_train = y_train[:50000]\n","\n","n_classes = 10\n","n_features = 784"]},{"cell_type":"markdown","metadata":{"id":"4CrVHw2BFnyG"},"source":["Predifined Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvtagtaQFnyH"},"outputs":[],"source":["def create_mini_batches(X, y, batch_size=64):\n","    mini_batches = []\n","    data = np.hstack((X, y))\n","    np.random.shuffle(data)\n","    n_classes = y.shape[1]\n","    n_minibatches = (data.shape[0] // batch_size)\n","  \n","    for i in range(n_minibatches):\n","        mini_batch = data[i * batch_size:(i + 1)*batch_size, :]\n","        X_mini = mini_batch[:, :-n_classes]\n","        Y_mini = mini_batch[:, -n_classes:]\n","        mini_batches.append((X_mini, Y_mini))\n","    \n","    if data.shape[0] % batch_size != 0:\n","        mini_batch = data[n_minibatches * batch_size:data.shape[0]]\n","        X_mini = mini_batch[:, :-n_classes]\n","        Y_mini = mini_batch[:, -n_classes:]\n","        mini_batches.append((X_mini, Y_mini))\n","        \n","    return mini_batches"]},{"cell_type":"markdown","metadata":{"id":"Qzpzls1gFnyN"},"source":["Multi-Class Logistic Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":91814,"status":"ok","timestamp":1657286658458,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"PPDquTM9FnyO","outputId":"e67054e6-6ce4-4096-a5d1-530f050b5e67"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch:   10,  loss: -0.05188338\n","Epoch:   20,  loss: -0.03254426\n","Epoch:   30,  loss: -0.04685844\n","Epoch:   40,  loss: -0.03023202\n","Epoch:   50,  loss: -0.02373058\n"]}],"source":["alpha = 0.01\n","\n","bias = tf.Variable(tf.zeros((n_classes,)))\n","wegt = tf.Variable(tf.random.uniform((n_features, n_classes))) # define w as (n_feature x n_classes)\n","\n","n_epochs = 50\n","\n","for epoch in range(n_epochs):\n","    # get mini batch\n","    mini_batches = create_mini_batches(X_train, y_train, batch_size=64)\n","\n","    for mini_batch in mini_batches:\n","        X_mini, y_mini = mini_batch\n","        mb_len = X_mini.shape[0]\n","\n","        ### START CODE HERE ###\n","        \n","        # Forward Prediction Path\n","        pout = tf.nn.softmax(tf.matmul(X_mini, wegt) + bias)             # Linear Prediction & Softmax\n","\n","        # Backward Gradient Path\n","        diff = pout - y_mini             # Find error\n","        X_tr = tf.transpose(X_mini)             # transpose input for backpropagation\n","        wegt = wegt - alpha * tf.matmul(X_tr, diff) / mb_len             # update weights with gradient decent\n","        bias = bias - alpha * tf.reduce_mean(diff, axis=0)             # update bias with gradient decent\n","\n","    # Just to show progress\n","    if ((epoch+1)%10==0):\n","        y_prb = tf.nn.softmax(tf.matmul(X_mini, wegt) + bias)            # forward path\n","        y_prd = y_mini * tf.math.log(y_prb)            # y * log(y_hat)\n","        loss_J = -tf.reduce_mean(y_prd).numpy()           # calculate crossentropy, then typecast to numpy\n","\n","        ### END CODE HERE ###\n","        print('Epoch: %4d,  loss: %10.8f' % (epoch+1, loss_J))"]},{"cell_type":"markdown","metadata":{"id":"Vq-KrlOCFnyQ"},"source":["Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1657286658459,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"38Eu-HmIFnyS","outputId":"584d22a0-0516-456c-b284-945a6b84afd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["[7 2 1 0 4 1 4 9 5 9]\n","[7 2 1 0 4 1 4 9 6 9]\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9138"]},"metadata":{},"execution_count":8}],"source":["from sklearn.metrics import accuracy_score\n","\n","y_prob = tf.nn.softmax(tf.matmul(X_test, wegt) + bias)\n","y_pred = tf.math.argmax(y_prob, axis=1)\n","\n","print(y_test[0:10])\n","print(y_pred[0:10].numpy())\n","\n","accuracy_score(y_pred, y_test)"]},{"cell_type":"markdown","metadata":{"id":"-4ngxCJDFnyU"},"source":["Using GradientTape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145390,"status":"ok","timestamp":1657287446935,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"O8MKmLgBFnyU","outputId":"541a4247-15e2-487c-f709-d9c5ed4f8d7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch:   10,  loss: 0.10319565\n","Epoch:   20,  loss: 0.04021993\n","Epoch:   30,  loss: 0.02826432\n","Epoch:   40,  loss: 0.07771918\n","Epoch:   50,  loss: 0.03368280\n"]}],"source":["bias = tf.Variable(tf.zeros((n_classes,)))\n","wegt = tf.Variable(tf.random.uniform((n_features,n_classes)))\n","\n","# decide optimizer: Gradient Descent with Momentum\n","opt = tf.optimizers.SGD(learning_rate=0.01)\n","\n","n_epochs = 50\n","\n","for epoch in range(n_epochs):\n","    # get mini batch\n","    mini_batches = create_mini_batches(X_train, y_train, batch_size=64)\n","\n","    for mini_batch in mini_batches:\n","        X_mini, y_mini = mini_batch\n","        mb_len = X_mini.shape[0]\n","\n","        # Forward Prediction Path\n","        with tf.GradientTape() as tape:\n","            ### START CODE HERE ###\n","\n","            prob = tf.nn.softmax(tf.matmul(X_mini, wegt) + bias)         # Find Probability\n","            prod = y_mini * tf.math.log(prob)         # Multiply log odds to ground truth\n","            loss = -tf.reduce_mean(prod)         # Calculate loss value; do NOT change to numpy\n","            \n","            ### END CODE HERE ###\n","\n","        # Backward Gradient Path\n","        grad = tape.gradient(loss,[wegt,bias])\n","        opt.apply_gradients(zip(grad,[wegt,bias]))\n","\n","    # Just to show progress\n","    if ((epoch+1)%10==0):\n","        ### START CODE HERE ###\n","\n","        y_prb = tf.nn.softmax(tf.matmul(X_mini, wegt) + bias)            # forward path\n","        y_prd = y_mini * tf.math.log(y_prb)            # y * log(y_hat)\n","        loss_J = -tf.reduce_mean(y_prd).numpy()           # calculate crossentropy, then typecast to numpy\n","\n","        ### END CODE HERE ###\n","        print('Epoch: %4d,  loss: %10.8f' % (epoch+1, loss_J))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":356,"status":"ok","timestamp":1657287452542,"user":{"displayName":"이충섭","userId":"17624345601773915567"},"user_tz":-540},"id":"dPhjwzpwFnyV","outputId":"9bc89d90-9cb8-4999-d0b6-f9bcb4e39ac9"},"outputs":[{"output_type":"stream","name":"stdout","text":["[7 2 1 0 4 1 4 9 5 9]\n","[7 2 1 0 4 1 4 9 6 9]\n"]},{"output_type":"execute_result","data":{"text/plain":["0.8603"]},"metadata":{},"execution_count":12}],"source":["from sklearn.metrics import accuracy_score\n","\n","y_prb = tf.nn.softmax(tf.matmul(X_test, wegt) + bias)\n","y_prd = tf.math.argmax(y_prb, axis=1)\n","\n","print(y_test[0:10])\n","print(y_prd[0:10].numpy())\n","\n","accuracy_score(y_prd, y_test)"]},{"cell_type":"code","source":[""],"metadata":{"id":"em_awreIB6JW"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"ML_L08_01_TF_dist.ipynb","provenance":[]},"interpreter":{"hash":"ab0787582b148005e56ebe9aaff49c38c248360ce5fb0676a65b6185761e7c4b"},"kernelspec":{"display_name":"Python 3.9.9 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}